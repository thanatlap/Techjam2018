{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Covariant Shift (Sa Model 2530)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thanatlapthawan/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "import xgboost as xgb\n",
    "\n",
    "import pickle\n",
    "from sklearn.externals import joblib\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read all data\n",
    "df_sa = pd.read_csv('prep_data/sa_summary_sorn_train.csv',index_col='ip_id')\n",
    "df_sa_test = pd.read_csv('prep_data/sa_summary_sorn_test.csv',index_col='ip_id')\n",
    "df_demo = pd.read_csv('data/demo.csv',index_col='ip_id')\n",
    "df_y_train = pd.read_csv('data/y_train.csv',index_col='ip_id')\n",
    "df_y_test = pd.read_csv('data/y_test_index.csv',index_col='ip_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Fix the column in df_sa_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sa_test['n_CR_EDC'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['label'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "sa_cols = df_sa.columns\n",
    "sa_test_cols = df_sa_test.columns\n",
    "\n",
    "common_cols = sa_cols.intersection(sa_test_cols)\n",
    "train_not_test = sa_cols.difference(sa_test_cols)\n",
    "print(train_not_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sa_all = pd.concat([df_sa.drop(['label'],axis=1),df_sa_test],axis=0,sort=True)\n",
    "df = df_demo.join(df_sa_all,how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9963, 46)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3602, 46)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = df_demo[df_demo.index.isin(df_y_test.index)].join(df_sa_test,how='inner')\n",
    "df_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Scope the data of df_test to 2530 (have no cc, have sa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2530, 46)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = df_test[df_test.index.isin(pd.read_csv('data/cc_txn.csv')['ip_id'])==False]\n",
    "df_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manage the categorical data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot  Option 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.drop(['act_strt_dt'],axis=1,inplace=True)\n",
    "# dummy = pd.get_dummies(df[df.select_dtypes('object').columns.tolist()])\n",
    "# df = pd.concat([dummy,df[df.select_dtypes(['int64','float64']).columns.tolist()]],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_test = pd.get_dummies(df_test[df_test.select_dtypes('object').columns.tolist()])\n",
    "# df_test = pd.concat([dummy,df_test[df_test.select_dtypes(['int64','float64']).columns.tolist()]],axis=1)\n",
    "# df_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop Option 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df.select_dtypes('object').columns.tolist(),axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.drop(df_test.select_dtypes('object').columns.tolist(),axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Label \"is_train\" 0 or 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['is_train'] = np.where(df.index.isin(df_y_train.index),1,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection\n",
    "- Find the feature which have the same distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_select(df_all, thres = 0.5):\n",
    "    res = 1\n",
    "    while res > thres:\n",
    "        columns = df_all.columns.tolist()\n",
    "\n",
    "        y = df_all['is_train'].values\n",
    "        X = df_all.drop(['is_train'],axis=1).values\n",
    "        X_train, X_val, y_train, y_test = train_test_split(X,y,test_size=0.2,stratify=y,random_state=0)\n",
    "        \n",
    "        \n",
    "        rfc = RandomForestClassifier(n_jobs=-1, max_depth=5, min_samples_leaf = 5,\n",
    "                                    n_estimators=100)\n",
    "        rfc.fit(X_train,y_train)\n",
    "        res_prob = rfc.predict_proba(X_val)[:, 1]\n",
    "\n",
    "        fpr, tpr, thresholds = metrics.roc_curve(y_test.ravel(), res_prob, pos_label=1)\n",
    "        res = metrics.auc(fpr, tpr)\n",
    "        \n",
    "        if res > thres:\n",
    "            df_all= df_all.drop([columns[rfc.feature_importances_.argmax()]],axis=1)\n",
    "    \n",
    "    print(res)\n",
    "    return df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5247657865124433\n"
     ]
    }
   ],
   "source": [
    "df_select = feature_select(df,0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>no_of_dpnd_chl</th>\n",
       "      <th>gnd_cd</th>\n",
       "      <th>n_CR_EDC</th>\n",
       "      <th>is_train</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ip_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       no_of_dpnd_chl  gnd_cd  n_CR_EDC  is_train\n",
       "ip_id                                            \n",
       "1                 0.0     2.0       0.0         1\n",
       "2                 1.0     2.0       0.0         1\n",
       "3                 0.0     2.0       0.0         1\n",
       "4                 0.0     2.0       0.0         1\n",
       "5                 1.0     2.0       0.0         1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_select.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_features = df[df.index.isin(df_y_train.index)][[col for col in df_select.drop(['is_train'],axis=1).columns]]\n",
    "df_train_label = df_y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA-Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import decomposition\n",
    "\n",
    "pca = decomposition.PCA(n_components=3)\n",
    "pca.fit(df_train_features)\n",
    "pca_df_train_features = pca.transform(df_train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.35174383,  0.49031352, -0.01237142],\n",
       "       [ 0.64808791,  0.50863384, -0.0114448 ],\n",
       "       [-0.35174383,  0.49031352, -0.01237142],\n",
       "       ...,\n",
       "       [ 4.66573894, -0.41790808, -0.01195628],\n",
       "       [-0.35174383,  0.49031352, -0.01237142],\n",
       "       [-0.35174383,  0.49031352, -0.01237142]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_df_train_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_features['pc1'] = pca_df_train_features[:,0]\n",
    "df_train_features['pc2'] = pca_df_train_features[:,1]\n",
    "df_train_features['pc3'] = pca_df_train_features[:,2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use the selected feature to build a credit model with randomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thanatlapthawan/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:95: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/thanatlapthawan/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:128: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/thanatlapthawan/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. ... 1. 0. 0.]\n",
      "0.635074600192197\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# clf1 = LogisticRegression(solver='lbfgs', multi_class='multinomial',random_state=1)\n",
    "clf2 = RandomForestClassifier(n_estimators=100,min_samples_leaf=5 ,n_jobs=-1,class_weight='balanced')\n",
    "clf3 = RandomForestClassifier(n_estimators=50,min_samples_leaf=10, max_depth=10 ,n_jobs=-1,class_weight='balanced')\n",
    "clf4 = RandomForestClassifier(n_estimators=100,min_samples_leaf=20, max_depth=5 ,n_jobs=-1,class_weight='balanced')\n",
    "# clf3 = GaussianNB()\n",
    "# clf4 = MLPClassifier(solver='adam', alpha=1e-5, hidden_layer_sizes=(30,50,10,))\n",
    "clf5 = GradientBoostingClassifier(min_samples_leaf=5, max_depth=None)\n",
    "clf6 = GradientBoostingClassifier(min_samples_leaf=1, max_depth=10,learning_rate=0.01)\n",
    "clf7 = GradientBoostingClassifier(min_samples_leaf=8, max_depth=20,learning_rate=0.01)\n",
    "# X_train = df_train_features[:5000]\n",
    "# y_train = df_train_label[:5000]\n",
    "# eclf1 = VotingClassifier(estimators=[('lr', clf1), ('rf', clf2), ('gnb', clf3), ('nn',clf4), ('gdb',clf5)], voting='soft')\n",
    "# eclf1 = VotingClassifier(estimators=[('rf', clf2), ('nn',clf4), ('gdb',clf5)], voting='soft')\n",
    "eclf1 = VotingClassifier(estimators=[('rf', clf2),('rf2', clf3),('rf3', clf4) ,('gdb',clf5),('gdb2',clf6),('gdb3',clf7)], voting='soft',n_jobs=-1)\n",
    "eclf1 = eclf1.fit(df_train_features, df_train_label)\n",
    "print(eclf1.predict(df_train_features))\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "y_true = df_train_label\n",
    "y_scores = eclf1.predict_proba(df_train_features)[:,1]\n",
    "print (roc_auc_score(y_true, y_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use the trained model to predict the test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA-Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_test[df_test.index.isin(df_y_test.index)][[col for col in df_select.drop(['is_train'],axis=1).columns]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_df_test_features = pca.transform(df_test)\n",
    "\n",
    "df_test['pc1'] = pca_df_test_features[:,0]\n",
    "df_test['pc2'] = pca_df_test_features[:,1]\n",
    "df_test['pc3'] = pca_df_test_features[:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = eclf1.predict_proba(df_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['prob1'] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test[['prob1']].to_csv('nat_result_2530.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
